{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPxqlIDHKF3FdNJFj80ay+A"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!apt-get install -y ffmpeg libsm6 libxext6\n","!apt-get install -y tesseract-ocr\n","!apt-get install -y portaudio19-dev\n","\n","!pip install streamlit\n","!pip install pyngrok\n","!pip install pydub\n","!pip install sounddevice\n","!pip install wavio\n","!pip install numpy\n","!pip install openai-whisper\n","!pip install PyAudio\n","!pip install SpeechRecognition\n","\n","!pip install deep-translator\n","!pip install joblib\n","!pip install pandas\n","!pip install Pillow\n","!pip install praw\n","!pip install protobuf\n","!pip install pytesseract\n","!pip install Requests\n","!pip install scikit-learn\n","!pip install google-generativeai\n","\n","!pip install librosa\n","\n","!pip install tensorflow\n","!pip install numpy\n","!pip install opencv-python"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HOJDlXRdO_ws","executionInfo":{"status":"ok","timestamp":1731692156555,"user_tz":-330,"elapsed":94762,"user":{"displayName":"Arkapratim Ghosh","userId":"06118460502332503890"}},"outputId":"5bf82772-8163-41f2-ed14-50a84f294d5c"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","libsm6 is already the newest version (2:1.2.3-1build2).\n","libxext6 is already the newest version (2:1.3.4-1build1).\n","ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n","0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","tesseract-ocr is already the newest version (4.1.1-2.1build1).\n","0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n","Reading package lists... Done\n","Building dependency tree... Done\n","Reading state information... Done\n","portaudio19-dev is already the newest version (19.6.0-1.1).\n","0 upgraded, 0 newly installed, 0 to remove and 49 not upgraded.\n","Requirement already satisfied: streamlit in /usr/local/lib/python3.10/dist-packages (1.40.1)\n","Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n","Requirement already satisfied: blinker<2,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.9.0)\n","Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n","Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n","Requirement already satisfied: numpy<3,>=1.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.26.4)\n","Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.2)\n","Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.2.2)\n","Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (11.0.0)\n","Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.25.5)\n","Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (17.0.0)\n","Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.32.3)\n","Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.9.4)\n","Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n","Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n","Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n","Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n","Requirement already satisfied: pydeck<1,>=0.8.0b4 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.9.1)\n","Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n","Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.0.0)\n","Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.21.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n","Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.2.1)\n","Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n","Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (0.25.1)\n","Requirement already satisfied: sounddevice in /usr/local/lib/python3.10/dist-packages (0.5.1)\n","Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.10/dist-packages (from sounddevice) (1.17.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from CFFI>=1.0->sounddevice) (2.22)\n","Requirement already satisfied: wavio in /usr/local/lib/python3.10/dist-packages (0.0.9)\n","Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from wavio) (1.26.4)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n","Requirement already satisfied: openai-whisper in /usr/local/lib/python3.10/dist-packages (20240930)\n","Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.60.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (1.26.4)\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (2.5.0+cu121)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (4.66.6)\n","Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (10.5.0)\n","Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (0.8.0)\n","Requirement already satisfied: triton>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper) (3.1.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton>=2.0.0->openai-whisper) (3.16.1)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper) (0.43.0)\n","Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2024.9.11)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper) (2.32.3)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (3.1.4)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (2024.10.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch->openai-whisper) (1.3.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper) (2024.8.30)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper) (3.0.2)\n","Requirement already satisfied: PyAudio in /usr/local/lib/python3.10/dist-packages (0.2.14)\n","Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.10/dist-packages (3.11.0)\n","Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (2.32.3)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from SpeechRecognition) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->SpeechRecognition) (2024.8.30)\n","Requirement already satisfied: deep-translator in /usr/local/lib/python3.10/dist-packages (1.11.4)\n","Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from deep-translator) (4.12.3)\n","Requirement already satisfied: requests<3.0.0,>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from deep-translator) (2.32.3)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (2.6)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2024.8.30)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (1.4.2)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (2.2.2)\n","Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas) (1.26.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas) (2024.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n","Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (11.0.0)\n","Requirement already satisfied: praw in /usr/local/lib/python3.10/dist-packages (7.8.1)\n","Requirement already satisfied: prawcore<3,>=2.4 in /usr/local/lib/python3.10/dist-packages (from praw) (2.4.0)\n","Requirement already satisfied: update_checker>=0.18 in /usr/local/lib/python3.10/dist-packages (from praw) (0.18.0)\n","Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.10/dist-packages (from praw) (1.8.0)\n","Requirement already satisfied: requests<3.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from prawcore<3,>=2.4->praw) (2.32.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2024.8.30)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (4.25.5)\n","Requirement already satisfied: pytesseract in /usr/local/lib/python3.10/dist-packages (0.3.13)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.2)\n","Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (11.0.0)\n","Requirement already satisfied: Requests in /usr/local/lib/python3.10/dist-packages (2.32.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from Requests) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from Requests) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from Requests) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from Requests) (2024.8.30)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (1.5.2)\n","Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.26.4)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.13.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn) (3.5.0)\n","Requirement already satisfied: google-generativeai in /usr/local/lib/python3.10/dist-packages (0.8.3)\n","Requirement already satisfied: google-ai-generativelanguage==0.6.10 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (0.6.10)\n","Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.19.2)\n","Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.151.0)\n","Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.27.0)\n","Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.25.5)\n","Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.9.2)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.66.6)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.12.2)\n","Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.10->google-generativeai) (1.25.0)\n","Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.65.0)\n","Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.0)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.1)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n","Requirement already satisfied: httplib2<1.dev0,>=0.19.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n","Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n","Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n","Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai) (0.7.0)\n","Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai) (2.23.4)\n","Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai) (1.67.1)\n","Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.10->google-generativeai) (1.62.3)\n","Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1.dev0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.0)\n","Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.8.30)\n","Requirement already satisfied: librosa in /usr/local/lib/python3.10/dist-packages (0.10.2.post1)\n","Requirement already satisfied: audioread>=2.1.9 in /usr/local/lib/python3.10/dist-packages (from librosa) (3.0.1)\n","Requirement already satisfied: numpy!=1.22.0,!=1.22.1,!=1.22.2,>=1.20.3 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.26.4)\n","Requirement already satisfied: scipy>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.13.1)\n","Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.5.2)\n","Requirement already satisfied: joblib>=0.14 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.4.2)\n","Requirement already satisfied: decorator>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.4.2)\n","Requirement already satisfied: numba>=0.51.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.60.0)\n","Requirement already satisfied: soundfile>=0.12.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.12.1)\n","Requirement already satisfied: pooch>=1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.8.2)\n","Requirement already satisfied: soxr>=0.3.2 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.5.0.post1)\n","Requirement already satisfied: typing-extensions>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (4.12.2)\n","Requirement already satisfied: lazy-loader>=0.1 in /usr/local/lib/python3.10/dist-packages (from librosa) (0.4)\n","Requirement already satisfied: msgpack>=1.0 in /usr/local/lib/python3.10/dist-packages (from librosa) (1.1.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from lazy-loader>=0.1->librosa) (24.2)\n","Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba>=0.51.0->librosa) (0.43.0)\n","Requirement already satisfied: platformdirs>=2.5.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (4.3.6)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from pooch>=1.1->librosa) (2.32.3)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.20.0->librosa) (3.5.0)\n","Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.10/dist-packages (from soundfile>=0.12.1->librosa) (1.17.1)\n","Requirement already satisfied: pycparser in /usr/local/lib/python3.10/dist-packages (from cffi>=1.0->soundfile>=0.12.1->librosa) (2.22)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->pooch>=1.1->librosa) (2024.8.30)\n","Requirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.17.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n","Requirement already satisfied: flatbuffers>=24.3.25 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.3.25)\n","Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.6.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n","Requirement already satisfied: h5py>=3.10.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.12.1)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (18.1.1)\n","Requirement already satisfied: ml-dtypes<0.5.0,>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.4.1)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (24.2)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.25.5)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.32.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (75.1.0)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.5.0)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.12.2)\n","Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.67.1)\n","Requirement already satisfied: tensorboard<2.18,>=2.17 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.17.0)\n","Requirement already satisfied: keras>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.4.1)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.37.1)\n","Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.26.4)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.44.0)\n","Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (13.9.4)\n","Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.0.8)\n","Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras>=3.2.0->tensorflow) (0.13.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.7)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (0.7.2)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.18,>=2.17->tensorflow) (3.1.3)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.18,>=2.17->tensorflow) (3.0.2)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras>=3.2.0->tensorflow) (2.18.0)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras>=3.2.0->tensorflow) (0.1.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (1.26.4)\n","Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.10.0.84)\n","Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.26.4)\n"]}]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3x3BlrALI8kw","executionInfo":{"status":"ok","timestamp":1731692172049,"user_tz":-330,"elapsed":448,"user":{"displayName":"Arkapratim Ghosh","userId":"06118460502332503890"}},"outputId":"2aae205d-ea38-4450-b864-024d4502825d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Overwriting v4.py\n"]}],"source":["%%writefile v4.py\n","\n","import streamlit as st\n","import joblib\n","import pandas as pd\n","import praw\n","from PIL import Image\n","from deep_translator import GoogleTranslator\n","import requests\n","from io import BytesIO\n","from collections import Counter\n","import google.generativeai as genai\n","\n","import cv2\n","import numpy as np\n","import whisper\n","import tempfile\n","import os\n","from pydub import AudioSegment\n","import subprocess\n","\n","import re\n","import librosa\n","import librosa.display\n","import tensorflow as tf\n","\n","import pytesseract\n","\n","# Configure Tesseract and FFMPEG\n","pytesseract.pytesseract.tesseract_cmd = '/usr/bin/tesseract'\n","os.environ[\"FFMPEG_BINARY\"] = \"/usr/bin/ffmpeg\"\n","\n","# Load Whisper model for audio transcription\n","whisper_model = whisper.load_model(\"base\")\n","\n","# Load the saved logistic regression model and vectorizer\n","model = joblib.load('LRmodel.pkl')\n","vectorizer = joblib.load('LRvectorizer.pkl')\n","\n","# Initialize Reddit API\n","reddit = praw.Reddit(client_id='DAOso5_7CHzXzdtd-070fg',\n","                     client_secret='JtdGFRDM10avSQFYthzYUQNfLeI8rQ',\n","                     user_agent='Mental Health')\n","\n","# Configure Gemini API for wellbeing insights\n","genai.configure(api_key=\"AIzaSyD-pu0AuG2dbzzspRfgS8DjO10Ffh08JiU\")\n","generation_config = {\n","    \"temperature\": 1,\n","    \"top_p\": 0.95,\n","    \"top_k\": 40,\n","    \"max_output_tokens\": 8192,\n","    \"response_mime_type\": \"text/plain\",\n","}\n","gemini_model = genai.GenerativeModel(\n","    model_name=\"gemini-1.5-flash\",\n","    generation_config=generation_config,\n",")\n","\n","# Function to fetch text-based posts from Reddit\n","def fetch_user_text_posts(username):\n","    try:\n","        user = reddit.redditor(username)\n","        posts = [post.title + \" \" + post.selftext for post in user.submissions.new(limit=20)]\n","        return posts\n","    except Exception as e:\n","        st.write(f\"Error fetching text posts: {e}\")\n","        return []\n","\n","# Function to fetch image-based posts from Reddit and perform OCR\n","def fetch_user_images_and_extract_text(username):\n","    try:\n","        user = reddit.redditor(username)\n","        images = [post.url for post in user.submissions.new(limit=20) if post.url.endswith(('.jpg', '.jpeg', '.png', '.webp', '.bmp', '.tiff'))]\n","\n","        extracted_texts = []\n","        for image_url in images:\n","            try:\n","                response = requests.get(image_url)\n","                image = Image.open(BytesIO(response.content))\n","                st.image(image, caption=\"Fetched Image\", use_column_width=True)\n","\n","                extracted_text = extract_text_from_image(image)\n","                if extracted_text.strip():\n","                    translated_text = GoogleTranslator(source='auto', target='en').translate(extracted_text)\n","                    extracted_texts.append(translated_text)\n","                    st.write(\"Extracted and Translated Text from Image:\")\n","                    st.text(translated_text)\n","            except Exception as e:\n","                st.write(f\"Error processing image {image_url}: {e}\")\n","\n","        return extracted_texts\n","    except Exception as e:\n","        st.write(f\"Error fetching images: {e}\")\n","        return []\n","\n","# Function to classify text and display result\n","def classify_text(text):\n","    input_vectorized = vectorizer.transform([text])\n","    prediction_proba = model.predict_proba(input_vectorized)\n","\n","    issue_labels = model.classes_\n","    proba_df = pd.DataFrame(prediction_proba, columns=issue_labels).T\n","    proba_df.columns = ['Probability']\n","\n","    top_issue = proba_df['Probability'].idxmax()\n","    top_probability = proba_df['Probability'].max()\n","\n","    st.write(f\"The most likely mental health concern is: {top_issue} with a probability of {top_probability:.2%}\")\n","\n","    get_wellbeing_insight(text, top_issue)\n","\n","# Function to get wellbeing insights from Gemini model\n","def get_wellbeing_insight(text, top_issue):\n","    try:\n","        chat_session = gemini_model.start_chat(history=[])\n","        prompt = f\"\"\" The Ryff Scale is based on six factors: autonomy, environmental mastery, personal growth, positive relations with others, purpose in life, and self-acceptance. Higher total scores indicate higher psychological well-being. Following are explanations of each criterion, and an example statement from the Ryff Inventory to measure each criterion: Autonomy: High scores indicate that the respondent is independent and regulates his or her behavior independent of social pressures. An example statement for this criterion is \"I have confidence in my opinions, even if they are contrary to the general consensus.\" Environmental Mastery: High scores indicate that the respondent makes effective use of opportunities and has a sense of mastery in managing environmental factors and activities, including managing everyday affairs and creating situations to benefit personal needs. An example statement for this criterion is \"In general, I feel I am in charge of the situation in which I live.\"Personal Growth: High scores indicate that the respondent continues to develop, is welcoming to new experiences, and recognizes improvement in behavior and self over time. An example statement for this criterion is \"I think it is important to have new experiences that challenge how you think about yourself and the world.\"Positive Relations with Others: High scores reflect the respondent's engagement in meaningful relationships with others that include reciprocal empathy, intimacy, and affection. An example statement for this criterion is \"People would describe me as a giving person, willing to share my time with others.\" Purpose in Life: High scores reflect the respondent's strong goal orientation and conviction that life holds meaning. An example statement for this criterion is \"Some people wander aimlessly through life, but I am not one of them.\"Self-Acceptance: High scores reflect the respondent's positive attitude about his or her self. An example statement for this criterion is \"I like most aspects of my personality.\" Now, please use the above information, along with the mental health issue: {top_issue}, to generate a short paragraph for each of the following subtopics, discussing how the issue may relate to these factors of mental well-being: 1. **Autonomy**: How might {top_issue} impact a person's ability to be independent and self-regulate behavior? 2. **Environmental Mastery**: Discuss how {top_issue} may affect a person's ability to manage their environment and activities. 3. **Personal Growth**: What impact might {top_issue} have on an individual's development, openness to new experiences, and recognition of self-improvement? 4. **Positive Relations with Others**: How does {top_issue} influence the ability to maintain meaningful and empathetic relationships? 5. **Purpose in Life**: How might {top_issue} shape an individual's sense of purpose or goal orientation in life? 6. **Self-Acceptance**: What role does {top_issue} play in a person's self-image and acceptance of themselves? Based on these subtopics, provide practical advice to improve or reduce the impact of {top_issue}.\"\"\"\n","\n","        response = chat_session.send_message(prompt)\n","\n","        st.write(\"### Wellbeing Insight:\")\n","        st.write(response.text)\n","    except Exception as e:\n","        st.write(f\"Error retrieving wellbeing insights: {e}\")\n","\n","# Function to extract text from image using Tesseract\n","def extract_text_from_image(image):\n","    extracted_text = pytesseract.image_to_string(image)\n","    return extracted_text.splitlines()\n","\n","# Function to extract text from an image using Tesseract\n","def extract_text_from_image_video(image):\n","    extracted_text = pytesseract.image_to_string(image)\n","    return extracted_text if extracted_text else \"\"  # Return empty string if no text is found\n","\n","\n","# Function to extract audio from a video file and classify it\n","# Function to extract 20 frames from a video file\n","def extract_frames(video_path, num_frames=20):\n","    cap = cv2.VideoCapture(video_path)\n","    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n","\n","    frames = []\n","    frame_interval = total_frames // num_frames  # Calculate frame interval\n","\n","    for i in range(num_frames):\n","        cap.set(cv2.CAP_PROP_POS_FRAMES, i * frame_interval)\n","\n","        ret, frame = cap.read()\n","\n","        if ret:\n","            frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n","            frames.append(frame)\n","\n","    cap.release()\n","    return frames\n","\n","\n","\n","def transcribe_audio_from_video(video_file):\n","    try:\n","        # Save the uploaded video file to a temporary file\n","        with tempfile.NamedTemporaryFile(delete=False, suffix=\".mp4\") as temp_video_file:\n","            temp_video_file.write(video_file.read())\n","            temp_video_path = temp_video_file.name\n","\n","        audio_path = tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False).name\n","\n","        # Extract audio from video using subprocess\n","        subprocess.run([\"ffmpeg\", \"-i\", temp_video_path, \"-q:a\", \"0\", \"-map\", \"a\", audio_path, \"-y\"])\n","        audio = AudioSegment.from_file(audio_path)\n","\n","        # Use Whisper to transcribe the audio\n","        result = whisper_model.transcribe(audio_path)\n","\n","        # Get the transcribed text and translate if necessary\n","        transcribed_text = result[\"text\"]\n","        translated_text = GoogleTranslator(source=\"auto\", target=\"en\").translate(transcribed_text)\n","\n","        # Clean up temporary files\n","        os.remove(temp_video_path)\n","        os.remove(audio_path)\n","\n","        return translated_text\n","\n","    except Exception as e:\n","        # Display a user-friendly message if the video is too long or another error occurs\n","        if \"duration\" in str(e).lower() or \"length\" in str(e).lower():\n","            return \"The video is too long to process. Please upload a shorter video.\"\n","        else:\n","            return f\"An error occurred: {e}\"\n","\n","# Function to translate text using DeepL\n","def translate_text(text, target_lang=\"en\"):\n","    try:\n","        if text:\n","            translated_text = GoogleTranslator(source=\"auto\", target=target_lang).translate(text)\n","            return translated_text\n","        return \"\"  # Return empty string if text is empty or None\n","    except Exception as e:\n","        return f\"Error translating text: {str(e)}\"\n","\n","# Function to extract audio from a video file\n","def extract_audio_from_video(video_path):\n","    try:\n","        # Generate a temporary audio file path\n","        audio_path = tempfile.NamedTemporaryFile(delete=False, suffix=\".wav\").name\n","\n","        # Use FFmpeg to extract audio from video\n","        subprocess.run([\"ffmpeg\", \"-i\", video_path, \"-q:a\", \"0\", \"-map\", \"a\", audio_path, \"-y\"])\n","\n","        # Return the path of the extracted audio\n","        return audio_path\n","\n","    except Exception as e:\n","        return f\"Error extracting audio: {str(e)}\"\n","\n","# Function to analyze audio mood based on extracted audio\n","def analyze_audio_mood(video_path):\n","    try:\n","        # Extract audio from the video (assuming extract_audio_from_video is implemented)\n","        audio_path = extract_audio_from_video(video_path)\n","\n","        # Load the audio file using librosa\n","        y, sr = librosa.load(audio_path)\n","\n","        # Extract MFCCs (Mel-frequency cepstral coefficients) from the audio signal\n","        mfcc = librosa.feature.mfcc(y=y, sr=sr, n_mfcc=13)\n","\n","        # Divide the MFCC array into 4 frequency bands and calculate scalar mean for each band\n","\n","        # Low Frequencies: MFCC 0, 1, 2\n","        low_freq_mfcc = np.mean(mfcc[0:3], axis=1)\n","        mean_low = np.mean(low_freq_mfcc)  # Scalar mean for low frequencies\n","\n","        # Mid-Low Frequencies: MFCC 3, 4\n","        mid_low_freq_mfcc = np.mean(mfcc[3:5], axis=1)\n","        mean_mid_low = np.mean(mid_low_freq_mfcc)  # Scalar mean for mid-low frequencies\n","\n","        # Mid-High Frequencies: MFCC 5, 6, 7\n","        mid_high_freq_mfcc = np.mean(mfcc[5:8], axis=1)\n","        mean_mid_high = np.mean(mid_high_freq_mfcc)  # Scalar mean for mid-high frequencies\n","\n","        # High Frequencies: MFCC 8, 9, 10, 11, 12\n","        high_freq_mfcc = np.mean(mfcc[8:13], axis=1)\n","        mean_high = np.mean(high_freq_mfcc)  # Scalar mean for high frequencies\n","\n","        # Now use these scalar means for classification\n","\n","        if mean_high <= mean_low and mean_high <= mean_mid_low and mean_high <= mean_mid_high:\n","            return \"Audio sounds normal, with no dominant emotion detected\"\n","\n","        elif mean_mid_high <= mean_low and mean_mid_high <= mean_mid_low and mean_mid_high <= mean_high:\n","            return \"Audio sounds neutral, calm, or peaceful\"\n","\n","        elif mean_mid_low <= mean_low and mean_mid_low <= mean_mid_high and mean_mid_low <= mean_high:\n","            return \"Audio sounds slightly melancholic or neutral\"\n","\n","        elif mean_low <= mean_mid_low and mean_low <= mean_mid_high and mean_low <= mean_high:\n","            return \"Audio sounds calm or melancholic, with less intensity\"\n","\n","        elif mean_high > mean_low and mean_high > mean_mid_low and mean_high <= mean_mid_high:\n","            return \"Audio sounds depressive or anxious in nature\"\n","\n","        else :\n","            return \"Audio sounds upbeat and energetic (Happy)\"\n","\n","    except Exception as e:\n","        return f\"Error analyzing audio mood: {str(e)}\"\n","\n","\n","# Define the Streamlit app\n","def run_app():\n","    st.title(\"Mental Health Disorder Detection\")\n","\n","    option = st.sidebar.selectbox(\n","        \"Choose an option\",\n","        [\"Text Input\", \"Image Upload\", \"Video Upload\", \"Reddit Username Analysis\"]\n","    )\n","\n","    # Text Input\n","    if option == \"Text Input\":\n","        st.subheader(\"Enter Text to Classify Mental Health Issue\")\n","        input_text = st.text_area(\"Enter your text here:\")\n","\n","        if st.button(\"Classify Text\"):\n","            if input_text.strip() == \"\":\n","                st.write(\"Please enter some text to classify.\")\n","            else:\n","                translated_text = GoogleTranslator(source='auto', target='en').translate(input_text)\n","                st.write(\"Translated Text (to English):\")\n","                st.write(translated_text)\n","                classify_text(translated_text)\n","\n","    # Image Upload\n","    elif option == \"Image Upload\":\n","        st.subheader(\"Upload an Image to Extract and Classify Text\")\n","        uploaded_image = st.file_uploader(\"Upload an Image\", type=[\"jpg\", \"jpeg\", \"png\", \"webp\", \"bmp\", \"tiff\"])\n","\n","        if uploaded_image is not None:\n","            image = Image.open(uploaded_image)\n","            st.image(image, caption=\"Uploaded Image\", use_column_width=True)\n","\n","            extracted_text = extract_text_from_image(image)\n","            translated_text = GoogleTranslator(source='auto', target='en').translate(\"\\n\".join(extracted_text))\n","\n","            st.subheader(\"Translated Text (to English)\")\n","            st.text(translated_text)\n","\n","            if st.button(\"Classify Extracted Text\"):\n","                if not translated_text or translated_text.strip() == \"\":\n","                    # If translated_text is empty or contains only whitespace\n","                    st.write(\"It is normal with probability 100%\")\n","                else:\n","                    classify_text(translated_text)\n","\n","    # Video Upload\n","    elif option == \"Video Upload\":\n","        st.subheader(\"Upload a Video to Extract and Classify Text\")\n","        # File upload widget\n","        video_file = st.file_uploader(\"Choose a video file\", type=[\"mp4\", \"mov\", \"avi\"])\n","\n","        if video_file:\n","            # Save the uploaded video file temporarily\n","            video_path = \"/tmp/uploaded_video.mp4\"\n","            with open(video_path, \"wb\") as f:\n","                f.write(video_file.getbuffer())\n","\n","            st.video(video_file)  # Display the uploaded video\n","\n","            # Extract frames from the uploaded video\n","            frames = extract_frames(video_path)\n","            combined_text = \"\"\n","\n","            st.write(\"Extracting frames from video ...\")\n","            for idx, frame in enumerate(frames):\n","                st.image(frame, caption=f\"Frame {idx + 1}\", use_column_width=True)\n","                text_from_frame = extract_text_from_image_video(frame)\n","\n","                if text_from_frame and text_from_frame not in combined_text:\n","                    combined_text += text_from_frame + \" \"\n","\n","            st.write(\"Text Extracted from Video Frames:\")\n","            st.text(combined_text)\n","\n","            # Translate the extracted text from frames\n","            translated_frame_text = translate_text(combined_text)\n","            # st.write(\"Translated Text from Video Frames:\")\n","            # st.text(translated_frame_text)\n","\n","            # Extract audio and transcribe it\n","            # st.write(\"Transcribing Audio from Video...\")\n","            transcribed_audio_text = transcribe_audio_from_video(video_file)\n","\n","            st.write(\"Transcribed Audio Text:\")\n","            st.text(transcribed_audio_text)\n","\n","            translated_audio_text = translate_text(transcribed_audio_text)\n","            # st.write(\"Translated Audio Text:\")\n","            # st.text(translated_audio_text)\n","\n","            # Combine the text extracted from both images and audio\n","            full_combined_text = combined_text + \" \" + transcribed_audio_text\n","            st.write(\"Combined Extracted Text (from both video frames and audio):\")\n","            st.text(full_combined_text)\n","\n","            translated_combined_text = translate_text(full_combined_text)\n","            st.write(\"Translated Combined Text (Frames + Audio):\")\n","            st.text(translated_combined_text)\n","\n","            # Analyze audio mood\n","            st.write(\"Analyzing Audio Mood...\")\n","            mood_result = analyze_audio_mood(video_path)\n","            st.write(mood_result)\n","\n","            cleaned_text = re.sub(r\"[^a-zA-Z0-9.,!? ]\", \"\", translated_combined_text)\n","\n","            if st.button(\"Classify Extracted Text\"):\n","                if not cleaned_text or cleaned_text.strip() == \"\":\n","                    # If audio_text is empty or contains only whitespace\n","                    st.write(\"It is normal with probability 100%\")\n","                else:\n","                    classify_text(cleaned_text)\n","\n","\n","    # Reddit Username Analysis\n","    elif option == \"Reddit Username Analysis\":\n","        st.subheader(\"Enter Reddit Username for Analysis\")\n","        username = st.text_input(\"Enter Reddit username:\")\n","\n","        if st.button(\"Analyze\"):\n","            if username.strip() == \"\":\n","                st.write(\"Please enter a Reddit username.\")\n","            else:\n","                # Fetch and display text posts\n","                text_posts = fetch_user_text_posts(username)\n","                if text_posts:\n","                    st.write(\"Recent Text Posts:\")\n","                    st.write(text_posts[:3])  # Display a few posts for review\n","\n","                # Fetch and display image-based posts with extracted text\n","                image_texts = fetch_user_images_and_extract_text(username)\n","\n","                # Combine text from both text posts and image text\n","                all_text = text_posts + image_texts\n","                if all_text:\n","                    predictions = []\n","                    for text in all_text:\n","                        # Vectorize and classify each post\n","                        input_vectorized = vectorizer.transform([text])\n","                        prediction = model.predict(input_vectorized)\n","                        predictions.append(prediction[0])\n","\n","                    # Count the most common mental health issue\n","                    issue_counts = Counter(predictions)\n","                    top_issue, top_count = issue_counts.most_common(1)[0]\n","                    top_percentage = (top_count / len(predictions)) * 100\n","\n","                    st.write(f\"The most frequently detected mental health concern is: {top_issue} appearing in {top_percentage:.2f}% of analyzed text.\")\n","                    issue_distribution = pd.DataFrame(issue_counts.items(), columns=['Mental Health Issue', 'Count'])\n","                    st.write(\"Mental health issue distribution across posts:\")\n","                    st.write(issue_distribution)\n","\n","                    # Call the Gemini model to get well-being insights\n","                    get_wellbeing_insight(\" \".join(all_text), top_issue)\n","                else:\n","                    st.write(\"No valid text found for analysis.\")\n","\n","# Run the app\n","if __name__ == '__main__':\n","    run_app()"]},{"cell_type":"code","source":["# Import ngrok\n","from pyngrok import ngrok\n","\n","# Set your authtoken\n","ngrok.set_auth_token(\"2ohUKqk37HcGbvwN0s8Y1E2WNxE_39z1gVF3bYq9vFSEm7Wzq\") # Replace YOUR_AUTHTOKEN with your actual authtoken\n","\n","# Kill any existing ngrok processes\n","ngrok.kill()\n","\n","# Start Streamlit with nohup\n","!nohup streamlit run v4.py &\n","\n","# Create a public URL with ngrok to access the app\n","public_url = ngrok.connect(addr='8501')\n","print(f\"Public URL: {public_url}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"c7ZcU0SgQyyl","executionInfo":{"status":"ok","timestamp":1731692184381,"user_tz":-330,"elapsed":958,"user":{"displayName":"Arkapratim Ghosh","userId":"06118460502332503890"}},"outputId":"8173cdbf-cba7-45ac-dec2-e61ef7ed4dfe"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["nohup: appending output to 'nohup.out'\n","Public URL: NgrokTunnel: \"https://3a76-34-125-136-5.ngrok-free.app\" -> \"http://localhost:8501\"\n"]}]},{"cell_type":"code","source":["ngrok.kill()"],"metadata":{"id":"5B0zDwj4Ty0U"},"execution_count":null,"outputs":[]}]}