{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HTNjjeePT3G",
        "outputId": "f367e65b-f84a-4667-870a-995aee5ba663"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.40.0-py2.py3-none-any.whl.metadata (8.5 kB)\n",
            "Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<3,>=1.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.26.4)\n",
            "Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.1)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.1.4)\n",
            "Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (10.4.0)\n",
            "Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (14.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.32.3)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.8.1)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Collecting watchdog<6,>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-5.0.3-py3-none-manylinux2014_x86_64.whl.metadata (41 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.20.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n",
            "Downloading streamlit-1.40.0-py2.py3-none-any.whl (8.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m58.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m94.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading watchdog-5.0.3-py3-none-manylinux2014_x86_64.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.3/79.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: watchdog, smmap, pydeck, gitdb, gitpython, streamlit\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.43 pydeck-0.9.1 smmap-5.0.1 streamlit-1.40.0 watchdog-5.0.3\n",
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.2.1-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "Downloading pyngrok-7.2.1-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.2.1\n",
            "Collecting praw\n",
            "  Downloading praw-7.8.1-py3-none-any.whl.metadata (9.4 kB)\n",
            "Collecting prawcore<3,>=2.4 (from praw)\n",
            "  Downloading prawcore-2.4.0-py3-none-any.whl.metadata (5.0 kB)\n",
            "Collecting update_checker>=0.18 (from praw)\n",
            "  Downloading update_checker-0.18.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.10/dist-packages (from praw) (1.8.0)\n",
            "Requirement already satisfied: requests<3.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from prawcore<3,>=2.4->praw) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2024.8.30)\n",
            "Downloading praw-7.8.1-py3-none-any.whl (189 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.3/189.3 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading prawcore-2.4.0-py3-none-any.whl (17 kB)\n",
            "Downloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n",
            "Installing collected packages: update_checker, prawcore, praw\n",
            "Successfully installed praw-7.8.1 prawcore-2.4.0 update_checker-0.18.0\n",
            "Collecting easyocr\n",
            "  Downloading easyocr-1.7.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from easyocr) (2.4.1+cu121)\n",
            "Requirement already satisfied: torchvision>=0.5 in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.19.1+cu121)\n",
            "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from easyocr) (4.10.0.84)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.13.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from easyocr) (1.26.4)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from easyocr) (10.4.0)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from easyocr) (0.24.0)\n",
            "Collecting python-bidi (from easyocr)\n",
            "  Downloading python_bidi-0.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from easyocr) (6.0.2)\n",
            "Requirement already satisfied: Shapely in /usr/local/lib/python3.10/dist-packages (from easyocr) (2.0.6)\n",
            "Collecting pyclipper (from easyocr)\n",
            "  Downloading pyclipper-1.3.0.post6-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (9.0 kB)\n",
            "Collecting ninja (from easyocr)\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (1.13.3)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->easyocr) (2024.6.1)\n",
            "Requirement already satisfied: imageio>=2.33 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (2.35.1)\n",
            "Requirement already satisfied: tifffile>=2022.8.12 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (2024.8.30)\n",
            "Requirement already satisfied: packaging>=21 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (24.1)\n",
            "Requirement already satisfied: lazy-loader>=0.4 in /usr/local/lib/python3.10/dist-packages (from scikit-image->easyocr) (0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->easyocr) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->easyocr) (1.3.0)\n",
            "Downloading easyocr-1.7.2-py3-none-any.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyclipper-1.3.0.post6-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (912 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m912.2/912.2 kB\u001b[0m \u001b[31m45.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_bidi-0.6.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (286 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.8/286.8 kB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: python-bidi, pyclipper, ninja, easyocr\n",
            "Successfully installed easyocr-1.7.2 ninja-1.11.1.1 pyclipper-1.3.0.post6 python-bidi-0.6.3\n",
            "Collecting deep-translator\n",
            "  Downloading deep_translator-1.11.4-py3-none-any.whl.metadata (30 kB)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from deep-translator) (4.12.3)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from deep-translator) (2.32.3)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (2.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2024.8.30)\n",
            "Downloading deep_translator-1.11.4-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: deep-translator\n",
            "Successfully installed deep-translator-1.11.4\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (10.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit\n",
        "!pip install pyngrok\n",
        "!pip install praw\n",
        "!pip install easyocr\n",
        "!pip install deep-translator\n",
        "!pip install pillow"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app_combined3.py\n",
        "\n",
        "import streamlit as st\n",
        "import joblib\n",
        "import pandas as pd\n",
        "import praw\n",
        "import easyocr\n",
        "from PIL import Image\n",
        "from deep_translator import GoogleTranslator\n",
        "import requests\n",
        "from io import BytesIO\n",
        "from collections import Counter\n",
        "import google.generativeai as genai\n",
        "\n",
        "# Load the saved logistic regression model and vectorizer\n",
        "model = joblib.load('LRmodel.pkl')\n",
        "vectorizer = joblib.load('LRvectorizer.pkl')\n",
        "\n",
        "# Initialize OCR readers for supported language combinations\n",
        "reader_en_hi = easyocr.Reader(['en', 'hi'])  # Hindi + English\n",
        "reader_en_bn = easyocr.Reader(['en', 'bn'])  # Bengali + English\n",
        "reader_en_te = easyocr.Reader(['en', 'te'])  # Telugu + English\n",
        "reader = easyocr.Reader(['en', 'es', 'fr', 'de'])  # Independent languages without the need for 'en'\n",
        "\n",
        "\"\"\"\n",
        "Supported Languages:\n",
        "en: English\n",
        "hi: Hindi\n",
        "bn: Bengali\n",
        "te: Telugu (with English)\n",
        "es: Spanish\n",
        "fr: French\n",
        "de: German\n",
        "\"\"\"\n",
        "\n",
        "reddit = praw.Reddit(client_id='DAOso5_7CHzXzdtd-070fg',\n",
        "                     client_secret='JtdGFRDM10avSQFYthzYUQNfLeI8rQ',\n",
        "                     user_agent='Mental Health')\n",
        "\n",
        "# Configure the Gemini API for wellbeing mapping\n",
        "genai.configure(api_key=\"AIzaSyD-pu0AuG2dbzzspRfgS8DjO10Ffh08JiU\")\n",
        "generation_config = {\n",
        "    \"temperature\": 1,\n",
        "    \"top_p\": 0.95,\n",
        "    \"top_k\": 40,\n",
        "    \"max_output_tokens\": 8192,\n",
        "    \"response_mime_type\": \"text/plain\",\n",
        "}\n",
        "gemini_model = genai.GenerativeModel(\n",
        "    model_name=\"gemini-1.5-flash\",\n",
        "    generation_config=generation_config,\n",
        ")\n",
        "\n",
        "# Function to fetch text-based posts from Reddit\n",
        "def fetch_user_text_posts(username):\n",
        "    try:\n",
        "        user = reddit.redditor(username)\n",
        "        posts = [post.title + \" \" + post.selftext for post in user.submissions.new(limit=20)]\n",
        "        return posts\n",
        "    except Exception as e:\n",
        "        st.write(f\"Error fetching text posts: {e}\")\n",
        "        return []\n",
        "\n",
        "# Function to fetch image-based posts from Reddit and perform OCR\n",
        "def fetch_user_images_and_extract_text(username):\n",
        "    try:\n",
        "        user = reddit.redditor(username)\n",
        "        images = [post.url for post in user.submissions.new(limit=20) if post.url.endswith(('.jpg', '.jpeg', '.png', '.webp', '.bmp', '.tiff'))]\n",
        "\n",
        "        extracted_texts = []\n",
        "        for image_url in images:\n",
        "            try:\n",
        "                response = requests.get(image_url)\n",
        "                image = Image.open(BytesIO(response.content))\n",
        "                st.image(image, caption=\"Fetched Image\", use_column_width=True)\n",
        "\n",
        "                # Extract text from image\n",
        "                extracted_text = extract_text_from_image(image, 'en')  # Default language is 'en'\n",
        "                extracted_text = \"\\n\".join(extracted_text)\n",
        "\n",
        "                # Translate to English if needed\n",
        "                if extracted_text.strip():\n",
        "                    translated_text = GoogleTranslator(source='auto', target='en').translate(extracted_text)\n",
        "                    extracted_texts.append(translated_text)\n",
        "                    st.write(\"Extracted and Translated Text from Image:\")\n",
        "                    st.text(translated_text)\n",
        "            except Exception as e:\n",
        "                st.write(f\"Error processing image {image_url}: {e}\")\n",
        "\n",
        "        return extracted_texts\n",
        "    except Exception as e:\n",
        "        st.write(f\"Error fetching images: {e}\")\n",
        "        return []\n",
        "\n",
        "# Function to classify text and display result\n",
        "def classify_text(text):\n",
        "    input_vectorized = vectorizer.transform([text])\n",
        "    prediction_proba = model.predict_proba(input_vectorized)\n",
        "\n",
        "    issue_labels = model.classes_\n",
        "    proba_df = pd.DataFrame(prediction_proba, columns=issue_labels).T\n",
        "    proba_df.columns = ['Probability']\n",
        "\n",
        "    top_issue = proba_df['Probability'].idxmax()\n",
        "    top_probability = proba_df['Probability'].max()\n",
        "\n",
        "    st.write(f\"The most likely mental health concern is: {top_issue} with a probability of {top_probability:.2%}\")\n",
        "\n",
        "    # Call the Gemini model to get well-being insights\n",
        "    get_wellbeing_insight(text, top_issue)\n",
        "\n",
        "# Function to get well-being insights from Gemini model\n",
        "def get_wellbeing_insight(text, top_issue):\n",
        "    try:\n",
        "        # Assuming you have a Gemini model API or client setup\n",
        "        chat_session = gemini_model.start_chat(history=[])\n",
        "        prompt = f\"Analyze the following text for mental wellbeing insights related to {top_issue}: {text}. Based on this, provide practical advice or actions the user can take to reduce or improve {top_issue}. Be supportive and provide actionable suggestions.\"\n",
        "        response = chat_session.send_message(prompt)\n",
        "\n",
        "        st.write(\"### Wellbeing Insight:\")\n",
        "        st.write(response.text)\n",
        "    except Exception as e:\n",
        "        st.write(f\"Error retrieving wellbeing insights: {e}\")\n",
        "\n",
        "# Function to extract text from image based on the language\n",
        "def extract_text_from_image(image, language):\n",
        "    if language == \"te\":  # Telugu requires 'en' and 'te'\n",
        "        reader_to_use = reader_en_te\n",
        "    elif language == \"hi\":  # Hindi with English\n",
        "        reader_to_use = reader_en_hi\n",
        "    elif language == \"bn\":  # Bengali with English\n",
        "        reader_to_use = reader_en_bn\n",
        "    else:\n",
        "        reader_to_use = reader  # Default reader for languages like Kannada, Marathi, etc.\n",
        "\n",
        "    # Perform OCR\n",
        "    extracted_text = reader_to_use.readtext(image, detail=0)\n",
        "    return extracted_text\n",
        "\n",
        "# Define the Streamlit app\n",
        "def run_app():\n",
        "    st.title(\"Mental Health Classifier App\")\n",
        "\n",
        "    # Option to choose functionality\n",
        "    option = st.sidebar.selectbox(\n",
        "        \"Choose an option\",\n",
        "        [\"Text Input\", \"Image Upload\", \"Reddit Username Analysis\"]\n",
        "    )\n",
        "\n",
        "    # 1. Text Input\n",
        "    if option == \"Text Input\":\n",
        "        st.subheader(\"Enter Text to Classify Mental Health Issue\")\n",
        "        input_text = st.text_area(\"Enter your text here:\")\n",
        "\n",
        "        if st.button(\"Classify Text\"):\n",
        "            if input_text.strip() == \"\":\n",
        "                st.write(\"Please enter some text to classify.\")\n",
        "            else:\n",
        "                # Translate if not in English\n",
        "                translated_text = GoogleTranslator(source='auto', target='en').translate(input_text)\n",
        "                st.write(\"Translated Text (to English):\")\n",
        "                st.write(translated_text)\n",
        "\n",
        "                # Classify and display result\n",
        "                classify_text(translated_text)\n",
        "\n",
        "    # 2. Image Upload\n",
        "    elif option == \"Image Upload\":\n",
        "        st.subheader(\"Upload an Image to Extract and Classify Text\")\n",
        "        uploaded_image = st.file_uploader(\"Upload an Image\", type=[\"jpg\", \"jpeg\", \"png\", \"webp\", \"bmp\", \"tiff\"])\n",
        "\n",
        "        if uploaded_image is not None:\n",
        "            image = Image.open(uploaded_image)\n",
        "            st.image(image, caption=\"Uploaded Image\", use_column_width=True)\n",
        "\n",
        "            # Extract text from image\n",
        "            extracted_text = extract_text_from_image(image, 'en')  # Default to 'en'\n",
        "            extracted_text = \"\\n\".join(extracted_text)\n",
        "\n",
        "            st.subheader(\"Extracted Text\")\n",
        "            st.text(extracted_text)\n",
        "\n",
        "            # Translate text to English if needed\n",
        "            translated_text = GoogleTranslator(source='auto', target='en').translate(extracted_text)\n",
        "            st.subheader(\"Translated Text (to English)\")\n",
        "            st.text(translated_text)\n",
        "\n",
        "            if st.button(\"Classify Extracted Text\"):\n",
        "                classify_text(translated_text)\n",
        "\n",
        "    # 3. Reddit Username Analysis\n",
        "    elif option == \"Reddit Username Analysis\":\n",
        "        st.subheader(\"Enter Reddit Username for Analysis\")\n",
        "        username = st.text_input(\"Enter Reddit username:\")\n",
        "\n",
        "        if st.button(\"Analyze\"):\n",
        "            if username.strip() == \"\":\n",
        "                st.write(\"Please enter a Reddit username.\")\n",
        "            else:\n",
        "                # Fetch and display text posts\n",
        "                text_posts = fetch_user_text_posts(username)\n",
        "                if text_posts:\n",
        "                    st.write(\"Recent Text Posts:\")\n",
        "                    st.write(text_posts[:3])  # Display a few posts for review\n",
        "\n",
        "                # Fetch and display image-based posts with extracted text\n",
        "                image_texts = fetch_user_images_and_extract_text(username)\n",
        "\n",
        "                # Combine text from both text posts and image text\n",
        "                all_text = text_posts + image_texts\n",
        "                if all_text:\n",
        "                    predictions = []\n",
        "                    for text in all_text:\n",
        "                        # Vectorize and classify each post\n",
        "                        input_vectorized = vectorizer.transform([text])\n",
        "                        prediction = model.predict(input_vectorized)\n",
        "                        predictions.append(prediction[0])\n",
        "\n",
        "                    # Count the most common mental health issue\n",
        "                    issue_counts = Counter(predictions)\n",
        "                    top_issue, top_count = issue_counts.most_common(1)[0]\n",
        "                    top_percentage = (top_count / len(predictions)) * 100\n",
        "\n",
        "                    st.write(f\"The most frequently detected mental health concern is: {top_issue} appearing in {top_percentage:.2f}% of analyzed text.\")\n",
        "                    issue_distribution = pd.DataFrame(issue_counts.items(), columns=['Mental Health Issue', 'Count'])\n",
        "                    st.write(\"Mental health issue distribution across posts:\")\n",
        "                    st.write(issue_distribution)\n",
        "\n",
        "                    # Call the Gemini model to get well-being insights\n",
        "                    get_wellbeing_insight(\" \".join(all_text), top_issue)\n",
        "                else:\n",
        "                    st.write(\"No valid text found for analysis.\")\n",
        "\n",
        "# Run the app\n",
        "if __name__ == '__main__':\n",
        "    run_app()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dHWrno3qQMxD",
        "outputId": "f22ae831-c6bb-4c63-bf23-48ccbafdeffe"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing app_combined3.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import ngrok\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Set your authtoken\n",
        "ngrok.set_auth_token(\"2ohUKqk37HcGbvwN0s8Y1E2WNxE_39z1gVF3bYq9vFSEm7Wzq\") # Replace YOUR_AUTHTOKEN with your actual authtoken\n",
        "\n",
        "# Kill any existing ngrok processes\n",
        "ngrok.kill()\n",
        "\n",
        "# Start Streamlit with nohup\n",
        "!nohup streamlit run app_combined3.py &\n",
        "\n",
        "# Create a public URL with ngrok to access the app\n",
        "public_url = ngrok.connect(addr='8501')\n",
        "print(f\"Public URL: {public_url}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PUXxWsPQ37U",
        "outputId": "95113714-8c7d-4511-aad5-6a34ddd4f7da"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nohup: appending output to 'nohup.out'\n",
            "Public URL: NgrokTunnel: \"https://852b-34-80-184-7.ngrok-free.app\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ngrok.kill()"
      ],
      "metadata": {
        "id": "KnOe6nTeXi3-"
      },
      "execution_count": 6,
      "outputs": []
    }
  ]
}