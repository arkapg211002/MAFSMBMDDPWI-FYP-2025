{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMWpv1wdffrV3K2muzo0dmP"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install streamlit\n","!pip install pyngrok\n","!pip install praw\n","!pip install pytesseract\n","!pip install deep-translator\n","!pip install pillow"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pE7zlifcdDku","executionInfo":{"status":"ok","timestamp":1731382883295,"user_tz":-330,"elapsed":36927,"user":{"displayName":"Arkapratim Ghosh","userId":"06118460502332503890"}},"outputId":"8a18afd0-7c09-4511-d9a2-5530b23a5030"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting streamlit\n","  Downloading streamlit-1.40.1-py2.py3-none-any.whl.metadata (8.5 kB)\n","Requirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n","Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n","Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.5.0)\n","Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n","Requirement already satisfied: numpy<3,>=1.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.26.4)\n","Requirement already satisfied: packaging<25,>=20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (24.1)\n","Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.2.2)\n","Requirement already satisfied: pillow<12,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (10.4.0)\n","Requirement already satisfied: protobuf<6,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n","Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (17.0.0)\n","Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.32.3)\n","Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.9.4)\n","Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.0.0)\n","Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n","Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.12.2)\n","Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.1.43)\n","Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n","  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n","Requirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n","Collecting watchdog<7,>=2.1.5 (from streamlit)\n","  Downloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl.metadata (44 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.4)\n","Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n","Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.11)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.4.0->streamlit) (2024.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.8.30)\n","Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n","Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.18.0)\n","Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.1)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\n","Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (24.2.0)\n","Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\n","Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.35.1)\n","Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.20.1)\n","Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.16.0)\n","Downloading streamlit-1.40.1-py2.py3-none-any.whl (8.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m56.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m77.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading watchdog-6.0.0-py3-none-manylinux2014_x86_64.whl (79 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/79.1 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: watchdog, pydeck, streamlit\n","Successfully installed pydeck-0.9.1 streamlit-1.40.1 watchdog-6.0.0\n","Collecting pyngrok\n","  Downloading pyngrok-7.2.1-py3-none-any.whl.metadata (8.3 kB)\n","Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n","Downloading pyngrok-7.2.1-py3-none-any.whl (22 kB)\n","Installing collected packages: pyngrok\n","Successfully installed pyngrok-7.2.1\n","Collecting praw\n","  Downloading praw-7.8.1-py3-none-any.whl.metadata (9.4 kB)\n","Collecting prawcore<3,>=2.4 (from praw)\n","  Downloading prawcore-2.4.0-py3-none-any.whl.metadata (5.0 kB)\n","Collecting update_checker>=0.18 (from praw)\n","  Downloading update_checker-0.18.0-py3-none-any.whl.metadata (2.3 kB)\n","Requirement already satisfied: websocket-client>=0.54.0 in /usr/local/lib/python3.10/dist-packages (from praw) (1.8.0)\n","Requirement already satisfied: requests<3.0,>=2.6.0 in /usr/local/lib/python3.10/dist-packages (from prawcore<3,>=2.4->praw) (2.32.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.6.0->prawcore<3,>=2.4->praw) (2024.8.30)\n","Downloading praw-7.8.1-py3-none-any.whl (189 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m189.3/189.3 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading prawcore-2.4.0-py3-none-any.whl (17 kB)\n","Downloading update_checker-0.18.0-py3-none-any.whl (7.0 kB)\n","Installing collected packages: update_checker, prawcore, praw\n","Successfully installed praw-7.8.1 prawcore-2.4.0 update_checker-0.18.0\n","Collecting pytesseract\n","  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n","Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (24.1)\n","Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (10.4.0)\n","Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n","Installing collected packages: pytesseract\n","Successfully installed pytesseract-0.3.13\n","Collecting deep-translator\n","  Downloading deep_translator-1.11.4-py3-none-any.whl.metadata (30 kB)\n","Requirement already satisfied: beautifulsoup4<5.0.0,>=4.9.1 in /usr/local/lib/python3.10/dist-packages (from deep-translator) (4.12.3)\n","Requirement already satisfied: requests<3.0.0,>=2.23.0 in /usr/local/lib/python3.10/dist-packages (from deep-translator) (2.32.3)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.9.1->deep-translator) (2.6)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.4.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2.2.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.23.0->deep-translator) (2024.8.30)\n","Downloading deep_translator-1.11.4-py3-none-any.whl (42 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.3/42.3 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: deep-translator\n","Successfully installed deep-translator-1.11.4\n","Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (10.4.0)\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ifSwwBUcbWmy","executionInfo":{"status":"ok","timestamp":1731382903701,"user_tz":-330,"elapsed":390,"user":{"displayName":"Arkapratim Ghosh","userId":"06118460502332503890"}},"outputId":"9d05531e-261b-4071-f003-839b46173b2e"},"outputs":[{"output_type":"stream","name":"stdout","text":["Writing v2.py\n"]}],"source":["%%writefile v2.py\n","\n","import streamlit as st\n","import joblib\n","import pandas as pd\n","import praw\n","import pytesseract\n","from PIL import Image\n","from deep_translator import GoogleTranslator\n","import requests\n","from io import BytesIO\n","from collections import Counter\n","import google.generativeai as genai\n","\n","# Load the saved logistic regression model and vectorizer\n","model = joblib.load('LRmodel.pkl')\n","vectorizer = joblib.load('LRvectorizer.pkl')\n","\n","# Initialize Reddit API\n","reddit = praw.Reddit(client_id='DAOso5_7CHzXzdtd-070fg',\n","                     client_secret='JtdGFRDM10avSQFYthzYUQNfLeI8rQ',\n","                     user_agent='Mental Health')\n","\n","# Configure the Gemini API for wellbeing mapping\n","genai.configure(api_key=\"AIzaSyD-pu0AuG2dbzzspRfgS8DjO10Ffh08JiU\")\n","generation_config = {\n","    \"temperature\": 1,\n","    \"top_p\": 0.95,\n","    \"top_k\": 40,\n","    \"max_output_tokens\": 8192,\n","    \"response_mime_type\": \"text/plain\",\n","}\n","gemini_model = genai.GenerativeModel(\n","    model_name=\"gemini-1.5-flash\",\n","    generation_config=generation_config,\n",")\n","\n","# Function to fetch text-based posts from Reddit\n","def fetch_user_text_posts(username):\n","    try:\n","        user = reddit.redditor(username)\n","        posts = [post.title + \" \" + post.selftext for post in user.submissions.new(limit=20)]\n","        return posts\n","    except Exception as e:\n","        st.write(f\"Error fetching text posts: {e}\")\n","        return []\n","\n","# Function to fetch image-based posts from Reddit and perform OCR\n","def fetch_user_images_and_extract_text(username):\n","    try:\n","        user = reddit.redditor(username)\n","        images = [post.url for post in user.submissions.new(limit=20) if post.url.endswith(('.jpg', '.jpeg', '.png', '.webp', '.bmp', '.tiff'))]\n","\n","        extracted_texts = []\n","        for image_url in images:\n","            try:\n","                response = requests.get(image_url)\n","                image = Image.open(BytesIO(response.content))\n","                st.image(image, caption=\"Fetched Image\", use_column_width=True)\n","\n","                # Extract text from image\n","                extracted_text = extract_text_from_image(image)\n","                extracted_text = \"\\n\".join(extracted_text)\n","\n","                # Translate to English if needed\n","                if extracted_text.strip():\n","                    translated_text = GoogleTranslator(source='auto', target='en').translate(extracted_text)\n","                    extracted_texts.append(translated_text)\n","                    st.write(\"Extracted and Translated Text from Image:\")\n","                    st.text(translated_text)\n","            except Exception as e:\n","                st.write(f\"Error processing image {image_url}: {e}\")\n","\n","        return extracted_texts\n","    except Exception as e:\n","        st.write(f\"Error fetching images: {e}\")\n","        return []\n","\n","# Function to classify text and display result\n","def classify_text(text):\n","    input_vectorized = vectorizer.transform([text])\n","    prediction_proba = model.predict_proba(input_vectorized)\n","\n","    issue_labels = model.classes_\n","    proba_df = pd.DataFrame(prediction_proba, columns=issue_labels).T\n","    proba_df.columns = ['Probability']\n","\n","    top_issue = proba_df['Probability'].idxmax()\n","    top_probability = proba_df['Probability'].max()\n","\n","    st.write(f\"The most likely mental health concern is: {top_issue} with a probability of {top_probability:.2%}\")\n","\n","    # Call the Gemini model to get well-being insights\n","    get_wellbeing_insight(text, top_issue)\n","\n","# Function to get well-being insights from Gemini model\n","def get_wellbeing_insight(text, top_issue):\n","    try:\n","        chat_session = gemini_model.start_chat(history=[])\n","        prompt = f\"Analyze the following text for mental wellbeing insights related to {top_issue}: {text}. Based on this, provide practical advice or actions the user can take to reduce or improve {top_issue}. Be supportive and provide actionable suggestions.\"\n","        response = chat_session.send_message(prompt)\n","\n","        st.write(\"### Wellbeing Insight:\")\n","        st.write(response.text)\n","    except Exception as e:\n","        st.write(f\"Error retrieving wellbeing insights: {e}\")\n","\n","# Function to extract text from image using Tesseract\n","def extract_text_from_image(image):\n","    extracted_text = pytesseract.image_to_string(image)\n","    return extracted_text.splitlines()\n","\n","# Define the Streamlit app\n","def run_app():\n","    st.title(\"Mental Health Classifier App\")\n","\n","    # Option to choose functionality\n","    option = st.sidebar.selectbox(\n","        \"Choose an option\",\n","        [\"Text Input\", \"Image Upload\", \"Reddit Username Analysis\"]\n","    )\n","\n","    # 1. Text Input\n","    if option == \"Text Input\":\n","        st.subheader(\"Enter Text to Classify Mental Health Issue\")\n","        input_text = st.text_area(\"Enter your text here:\")\n","\n","        if st.button(\"Classify Text\"):\n","            if input_text.strip() == \"\":\n","                st.write(\"Please enter some text to classify.\")\n","            else:\n","                # Translate if not in English\n","                translated_text = GoogleTranslator(source='auto', target='en').translate(input_text)\n","                st.write(\"Translated Text (to English):\")\n","                st.write(translated_text)\n","\n","                # Classify and display result\n","                classify_text(translated_text)\n","\n","    # 2. Image Upload\n","    elif option == \"Image Upload\":\n","        st.subheader(\"Upload an Image to Extract and Classify Text\")\n","        uploaded_image = st.file_uploader(\"Upload an Image\", type=[\"jpg\", \"jpeg\", \"png\", \"webp\", \"bmp\", \"tiff\"])\n","\n","        if uploaded_image is not None:\n","            image = Image.open(uploaded_image)\n","            st.image(image, caption=\"Uploaded Image\", use_column_width=True)\n","\n","            # Extract text from image\n","            extracted_text = extract_text_from_image(image)\n","            extracted_text = \"\\n\".join(extracted_text)\n","\n","            st.subheader(\"Extracted Text\")\n","            st.text(extracted_text)\n","\n","            # Translate text to English if needed\n","            translated_text = GoogleTranslator(source='auto', target='en').translate(extracted_text)\n","            st.subheader(\"Translated Text (to English)\")\n","            st.text(translated_text)\n","\n","            if st.button(\"Classify Extracted Text\"):\n","                classify_text(translated_text)\n","\n","    # 3. Reddit Username Analysis\n","    elif option == \"Reddit Username Analysis\":\n","        st.subheader(\"Enter Reddit Username for Analysis\")\n","        username = st.text_input(\"Enter Reddit username:\")\n","\n","        if st.button(\"Analyze\"):\n","            if username.strip() == \"\":\n","                st.write(\"Please enter a Reddit username.\")\n","            else:\n","                # Fetch and display text posts\n","                text_posts = fetch_user_text_posts(username)\n","                if text_posts:\n","                    st.write(\"Recent Text Posts:\")\n","                    st.write(text_posts[:3])  # Display a few posts for review\n","\n","                # Fetch and display image-based posts with extracted text\n","                image_texts = fetch_user_images_and_extract_text(username)\n","\n","                # Combine text from both text posts and image text\n","                all_text = text_posts + image_texts\n","                if all_text:\n","                    predictions = []\n","                    for text in all_text:\n","                        # Vectorize and classify each post\n","                        input_vectorized = vectorizer.transform([text])\n","                        prediction = model.predict(input_vectorized)\n","                        predictions.append(prediction[0])\n","\n","                    # Count the most common mental health issue\n","                    issue_counts = Counter(predictions)\n","                    top_issue, top_count = issue_counts.most_common(1)[0]\n","                    top_percentage = (top_count / len(predictions)) * 100\n","\n","                    st.write(f\"The most frequently detected mental health concern is: {top_issue} appearing in {top_percentage:.2f}% of analyzed text.\")\n","                    issue_distribution = pd.DataFrame(issue_counts.items(), columns=['Mental Health Issue', 'Count'])\n","                    st.write(\"Mental health issue distribution across posts:\")\n","                    st.write(issue_distribution)\n","\n","                    # Call the Gemini model to get well-being insights\n","                    get_wellbeing_insight(\" \".join(all_text), top_issue)\n","                else:\n","                    st.write(\"No valid text found for analysis.\")\n","\n","# Run the app\n","if __name__ == '__main__':\n","    run_app()\n"]},{"cell_type":"code","source":["# Import ngrok\n","from pyngrok import ngrok\n","\n","# Set your authtoken\n","ngrok.set_auth_token(\"2ohUKqk37HcGbvwN0s8Y1E2WNxE_39z1gVF3bYq9vFSEm7Wzq\") # Replace YOUR_AUTHTOKEN with your actual authtoken\n","\n","# Kill any existing ngrok processes\n","ngrok.kill()\n","\n","# Start Streamlit with nohup\n","!nohup streamlit run v2.py &\n","\n","# Create a public URL with ngrok to access the app\n","public_url = ngrok.connect(addr='8501')\n","print(f\"Public URL: {public_url}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IdTb9sqydpm-","executionInfo":{"status":"ok","timestamp":1731382940521,"user_tz":-330,"elapsed":1980,"user":{"displayName":"Arkapratim Ghosh","userId":"06118460502332503890"}},"outputId":"4fddc406-2de9-47ae-8f44-e50c650351cb"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["nohup: appending output to 'nohup.out'\n","Public URL: NgrokTunnel: \"https://bd0b-35-188-198-143.ngrok-free.app\" -> \"http://localhost:8501\"\n"]}]}]}